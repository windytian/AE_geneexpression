import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
plt.style.use('seaborn')
import tensorflow as tf
import seaborn as sns
from keras.models import Model
from keras.layers import Input, add
from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape
from keras.callbacks import ModelCheckpoint
from keras import regularizers
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_curve, auc, precision_recall_curve
from sklearn import preprocessing
from keras.models import load_model


#load data
os.chdir("D:\\shengxin\\AD\\AD+CA\\41")
dataLC = pd.read_table("LCKEGGgenesLCEXP.txt",header=0,index_col=0,)
dataLC = dataLC.transpose()
dataLC
dataAD = pd.read_table("ADKEGGgenesADEXP.txt",header=0,index_col=0,)
dataAD = dataAD.transpose()
dataAD
#dataADgenesLC
dataADgenesLC = pd.read_table("ADKEGGgenesLCEXP.txt",header=0,index_col=0,)
dataADgenesLC =dataADgenesLC.transpose()
dataADgenesLC
#dataLCgenesAD
dataLCgenesAD = pd.read_table("LCKEGGgenesADEXP.txt",header=0,index_col=0,)
dataLCgenesAD =dataLCgenesAD.transpose()
dataLCgenesAD


#minmax-nolmolized
minmax = preprocessing.MinMaxScaler()
dataLC_minmax = minmax.fit_transform(dataLC)
dataLC=dataLC_minmax
dataAD_minmax = minmax.fit_transform(dataAD)
dataAD=dataAD_minmax
dataADgenesLC_minmax = minmax.fit_transform(dataADgenesLC)
dataADgenesLC=dataADgenesLC_minmax
dataLCgenesAD_minmax = minmax.fit_transform(dataLCgenesAD)
dataLCgenesAD=dataLCgenesAD_minmax

#split train data and test data 
from sklearn import model_selection
from sklearn.model_selection import train_test_split
yLC_train,yLC_test = train_test_split(dataLC , train_size=0.4, random_state=0)
yLC_train = yLC_train.astype('float32')
yLC_test = yLC_test.astype('float32')
yAD_train,yAD_test = train_test_split(dataAD , train_size=0.4, random_state=0)
yAD_train = yAD_train.astype('float32')
yAD_test = yAD_test.astype('float32')

#the AE model based on Lung cancer related genes involved in the enriched KEGG pathways
input_img = Input(shape=(465,))
encoding_dim = 1

#encoder
encoded = Dense(128, activation='relu')(input_img)
encoded = Dropout(0.2)(encoded)
encoded = Dense(64, activation='relu')(encoded)
encoded = Dropout(0.2)(encoded)
encoded = Dense(10, activation='relu')(encoded)
encoded = Dropout(0.2)(encoded)
encoder_output = Dense(encoding_dim)(encoded)

#decoder
decoded = Dense(10, activation='relu')(encoder_output)
decoded = Dropout(0.2)(decoded)
decoded = Dense(64, activation='relu')(decoded)
decoded = Dropout(0.2)(decoded)
decoded = Dense(128, activation='relu')(decoded)
decoded = Dropout(0.2)(decoded)
decoded = Dense(465, activation='linear')(decoded)
autoencoder = Model(inputs=input_img, outputs=decoded)
# compile encoder
encoder = Model(inputs=input_img, outputs=encoder_output)
# compile autoencoder
autoencoder.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-09, amsgrad=False, name='Adam'), loss='mse', metrics=['mae'])

# save model as SofaSofa_model.h5, and train the model
checkpointer = ModelCheckpoint(filepath="SofaSofa_model_LC.h5",verbose=0, save_best_only=True)
history = autoencoder.fit(yLC_train, yLC_train, epochs=100, batch_size=128, shuffle=True, validation_data=(yLC_test, yLC_test), verbose=1, callbacks=[checkpointer]).history

# the reconstruction data based on encoder
pred_testLCLC = encoder.predict(dataLC)
pred_testLCAD = encoder.predict(dataLCgenesAD)





#the AE model based on Alzheimer's disease related genes involved in the enriched KEGG pathways
input_img = Input(shape=171,))
encoding_dim = 1

#encoder
encoded = Dense(128, activation='relu')(input_img)
encoded = Dropout(0.2)(encoded)
encoded = Dense(64, activation='relu')(encoded)
encoded = Dropout(0.2)(encoded)
encoded = Dense(10, activation='relu')(encoded)
encoded = Dropout(0.2)(encoded)
encoder_output = Dense(encoding_dim)(encoded)

#decoder
decoded = Dense(10, activation='relu')(encoder_output)
decoded = Dropout(0.2)(decoded)
decoded = Dense(64, activation='relu')(decoded)
decoded = Dropout(0.2)(decoded)
decoded = Dense(128, activation='relu')(decoded)
decoded = Dropout(0.2)(decoded)
decoded = Dense(171, activation='linear')(decoded)
autoencoder = Model(inputs=input_img, outputs=decoded)
# compile encoder
encoder = Model(inputs=input_img, outputs=encoder_output)
# compile autoencoder
autoencoder.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-09, amsgrad=False, name='Adam'), loss='mse', metrics=['mae'])

# save model as SofaSofa_model.h5, and train the model
checkpointer = ModelCheckpoint(filepath="SofaSofa_model_AD.h5",verbose=0, save_best_only=True)
history = autoencoder.fit(yAD_train, yAD_train, epochs=120, batch_size=128, shuffle=True, validation_data=(yAD_test, yAD_test), verbose=1, callbacks=[checkpointer]).history

# the reconstruction data based on encoder

pred_testADAD = encoder.predict(dataAD)
pred_testADLC = encoder.predict(dataADgenesLC)


plt.title('AD data')
plt.xlabel("Predicted values by the AD model")
plt.ylabel("Predicted values by the LC model")
plt.scatter(pred_testADAD, pred_testLCAD,s=10)
plt.show()

plt.title('LC data')
plt.xlabel("Predicted values by the LC model")
plt.ylabel("Predicted values by the AD model")
plt.scatter(pred_testLCLC, pred_testADLC,s=10)
plt.show()
